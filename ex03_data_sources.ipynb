{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a741660-eaff-49f7-9eac-ed9f709b6b8a",
   "metadata": {},
   "source": [
    "1 Use gamedata.json for this task. This file contains information of games sold through Steam. Parse out the following information from the data:\n",
    "- TOP 3 highest metacritic score. Present results using the following format: *Title* has metacritic score of *Score* (for example)\n",
    "- Games with price discount being 90 % or more. Present results using the following format: *Title* | Discount: *Savings* (for example Metal Gear Solid V: Ground Zeroes | Discount: 90.090090)\n",
    "- Games having metacritic score higher than steam score. Present results using the following format: *Title* has metacritic score of *MetacriticScore* and steam score of *SteamRatingPercent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb84c638-8729-43ec-b9d8-679de9842406",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22908\\4235985983.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load game data from JSON file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./Data-Analytics-Exercises/data_files/gamedata.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Function to get metacritic score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\roy\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\roy\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\roy\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\roy\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    744\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\roy\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"frame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"series\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\roy\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\roy\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m             self.obj = DataFrame(\n\u001b[1;32m-> 1133\u001b[1;33m                 \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m             )\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load game data from JSON file\n",
    "file = pd.read_json(\"./Data-Analytics-Exercises/data_files/gamedata.json\") \n",
    "\n",
    "# Function to get metacritic score\n",
    "def get_metacritic_score(game):\n",
    "    return game.get(\"metacriticScore\")\n",
    "\n",
    "# Function to get game discount\n",
    "def get_discount(game):\n",
    "    return float(game.get(\"savings\"))\n",
    "\n",
    "# Create game data copy and sort by metacritic score in descending order\n",
    "topgames = gamedata.copy()\n",
    "topgames.sort(key=get_metacritic_score, reverse=True)\n",
    "\n",
    "# Top 3 games with highest metacritic score\n",
    "print(\"Top 3 Games with the Highest Metacritic Score:\")\n",
    "for game in topgames[:3]:\n",
    "    print(f\"{game.get('title')} has a metacritic score of {game.get('metacriticScore')}.\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Games with 90% discount or more\n",
    "print(\"Games with a discount of 90% or more:\")\n",
    "discountedgames = gamedata.copy()\n",
    "for game in discountedgames:\n",
    "    discount = get_discount(game)\n",
    "    if discount >= 90:\n",
    "        print(f\"{game.get('title')} | {discount}%\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Games with higher metacritic score than Steam score\n",
    "print(\"Games with a Higher Metacritic Score than Steam Score:\")\n",
    "for game in gamedata:\n",
    "    steam_score = game.get(\"steamRatingPercent\")\n",
    "    metacritic_score = game.get(\"metacriticScore\")\n",
    "    if steam_score < metacritic_score:\n",
    "        \n",
    "        print(f\"{game.get('title')} has a metacritic score of {metacritic_score} and a steam score of {steam_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692b6ea-34d4-47e3-8d08-b3ba58bd10ac",
   "metadata": {},
   "source": [
    "2 Use earthquakes.csv for this task. This file contains information about earthquakes recorded between 1965 and 2016. Earthquake magnitude value describes how strong the earthquake is. Magnitude information can be categorized like presented in the table below (*Source: http://www.geo.mtu.edu/UPSeis/magnitude.html*).\n",
    "\n",
    "| Magnitude      | Class | Effects |\n",
    "|----------------|-------|---------|\n",
    "| 2.4 or less    | Minor | Usually not felt, but can be recorded by seismograph. |\n",
    "| 2.5 to 5.4     | Light | Often felt, but only causes minor damage. |\n",
    "| 5.5 to 6.0     | Moderate | Slight damage to buildings and other structures. |\n",
    "| 6.1 to 6.9     | Strong | May cause a lot of damage in very populated areas. |\n",
    "| 7.0 to 7.9     | Major | Major earthquake. Serious damage. |\n",
    "| 8.0 or greater | Great | Great earthquake. Can totally destroy communities near the epicenter. |\n",
    "\n",
    "Count how many earthquakes have occurred in each class.\n",
    "\n",
    "<b style=\"color:red;\">Notice:</b> The first value has been modified to be 2.4 or less compared to the original source (has been 2.5 or less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf9b33e-ec10-442b-92f3-4230e5df363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Minor': 0, 'Light': 0, 'Moderate': 17638, 'Strong': 5036, 'Major': 698, 'Great': 40}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv(\"./data_files/earthquakes.csv\",delimiter=\",\")\n",
    "\n",
    "quakes = {\n",
    "    \"Minor\": 0,\n",
    "    \"Light\": 0,\n",
    "    \"Moderate\": 0,\n",
    "    \"Strong\": 0,\n",
    "    \"Major\": 0,\n",
    "    \"Great\": 0\n",
    "}\n",
    "\n",
    "for x in file.iterrows():\n",
    "    mag = x[1].Magnitude\n",
    "    if mag <= 2.4:\n",
    "        quakes[\"Minor\"] += 1\n",
    "    elif mag <= 5.4:\n",
    "        quakes[\"Light\"] += 1\n",
    "    elif mag <= 6.0:\n",
    "        quakes[\"Moderate\"] += 1\n",
    "    elif mag <= 6.9:\n",
    "        quakes[\"Strong\"] += 1\n",
    "    elif mag <= 7.9:\n",
    "        quakes[\"Major\"] += 1\n",
    "    else:\n",
    "        quakes[\"Great\"] += 1\n",
    "\n",
    "print(quakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c3b3b-3a0f-46c3-81cf-75cf4cdb12ad",
   "metadata": {},
   "source": [
    "3 Use netflix_titles.xml for this task. This file contains information about Netflix movies and TV shows. **Important:** Movies have duration presented in minutes while TV shows have duration presented in amount of seasons! Parse out the following information from the data:\n",
    "- Movies released in 2017\n",
    "- TV show and movie amount (present both counts in separate lines)\n",
    "- Movies with a length between 15 and 20 minutes (values 15 and 20 included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b24a3b2-c395-4088-9ba0-f64a8344ffa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies released in 2017: 744 \n",
      "TV Shows: 2410 \n",
      "Movies: 5377\n",
      "Movies with a length between 15 and 20 minutes: 11\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse(\"./data_files/netflix_titles.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "nftitles = [{i.tag: j.text for i, j in zip(root[0], elem)} for elem in root]\n",
    "\n",
    "movies2017 = sum(1 for x in nftitles if x.get(\"type\") == \"Movie\" and \"2017\" in x.get(\"release_year\"))\n",
    "tv = sum(1 for x in nftitles if x.get(\"type\") == \"TV Show\")\n",
    "movies = sum(1 for x in nftitles if x.get(\"type\") == \"Movie\")\n",
    "checkmovies = sum(1 for x in nftitles if x.get(\"type\") == \"Movie\" and 15 <= int(x.get(\"duration\")[0:-3]) <= 20)\n",
    "\n",
    "print(f\"\"\"Movies released in 2017: {movies2017} \n",
    "TV Shows: {tv} \n",
    "Movies: {movies}\n",
    "Movies with a length between 15 and 20 minutes: {checkmovies}\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e38b2-e96e-49c2-aacc-411de9a2a246",
   "metadata": {},
   "source": [
    "4 Use the following Rest API for this task: https://tie.digitraffic.fi/api/v1/data/weather-data. Calculate the average for air temperature (ILMA) and humidity (ILMAN_KOSTEUS) values using two decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023ac830-ce8c-4177-9ac9-36f5c94f9211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average air temperature: 0.8\n",
      "Average air humidity: 73.51\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://tie.digitraffic.fi/api/v1/data/weather-data\"\n",
    "response = requests.get(url=url)\n",
    "weatherdata = response.json()\n",
    "\n",
    "# Initialize empty lists\n",
    "temperatures = []\n",
    "humidities = []\n",
    "\n",
    "for station in weatherdata[\"weatherStations\"]:\n",
    "    for sensor in station.get(\"sensorValues\"):\n",
    "        name = sensor.get(\"name\")\n",
    "        if name == \"ILMA\":\n",
    "            temperatures.append(sensor.get(\"sensorValue\"))\n",
    "        elif name == \"ILMAN_KOSTEUS\":\n",
    "            humidities.append(sensor.get(\"sensorValue\"))\n",
    "\n",
    "print(f\"Average air temperature: {round((sum(temperatures)/len(temperatures)),2)}\")\n",
    "print(f\"Average air humidity: {round((sum(humidities)/len(humidities)),2)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
